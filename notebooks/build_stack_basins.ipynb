{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ea7bcf9f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'api.maap-project.org'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from maap.maap import MAAP\n",
    "# maap = MAAP(maap_host='api.maap-project.org')\n",
    "maap = MAAP()\n",
    "maap._MAAP_HOST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2246e42d",
   "metadata": {},
   "source": [
    "# Run `build_stack_list` locally for a list of dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7041b2b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# For some reason this is needed to get s3fs to work in ExtractUtils\n",
    "# this upgrades to 0.3.4 even though we already specify this version in requirements_main...\n",
    "#!pip install s3fs --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5c541eee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xmltodict in /opt/conda/lib/python3.10/site-packages (0.13.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "import rasterstats\n",
    "import os\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import glob\n",
    "import datetime\n",
    "!pip install xmltodict\n",
    "import xmltodict\n",
    "import sys\n",
    "sys.path.append('/projects/code/icesat2_boreal/lib')\n",
    "import ExtractUtils\n",
    "import build_stack\n",
    "import random\n",
    "\n",
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "\n",
    "import contextily as ctx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4283ab1",
   "metadata": {},
   "source": [
    "### To run build_stack.py across a tiled raster dataset you need a bunch of args that we'll gather into a dictionary\n",
    "\n",
    "s3 you need to have a vector footprint of that dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df593ad",
   "metadata": {},
   "source": [
    "#### Dictionary preparation makes this script very flexible and transferable to another s3 dataset\n",
    "This dictionary is specific to the ESA Worldcover dataset.  \n",
    "To run '`build_stack.py` across another dataset, just prepare another dictionary here and everything below should be exactly the same.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1147899c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TILE_NUM = 8080279620"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f57e6230",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "INDEX_FN = 'https://maap-ops-workspace.s3.amazonaws.com/shared/montesano/databank/boreal_height_cmip6/hydrobasins_L08_patterns_tte_boreal_tundra_3995.gpkg'\n",
    "INDEX_LYR = 'hydrobasins_L08_patterns_tte_boreal_tundra_3995'\n",
    "OUTDIR = '/projects/my-public-bucket/databank/boreal_height_cmip6/output/build_stack_basin_clips'\n",
    "ZONAL_DIR = '/projects/my-public-bucket/databank/boreal_height_cmip6/output/zonal_stats'\n",
    "\n",
    "VECTOR_DICT = {\n",
    "                'INDEX_FN': INDEX_FN,\n",
    "                'ID_COL_NAME': 'HYBAS_ID',\n",
    "                'TILE_NUM':TILE_NUM,\n",
    "                'INDEX_LYR': INDEX_LYR,\n",
    "}\n",
    "\n",
    "BUILD_STACK_DICT_LIST = [\n",
    "                # tcc slope\n",
    "                {\n",
    "                            # #'INDEX_FN': '/projects/my-public-bucket/boreal_tiles_v003.gpkg',\n",
    "                            # 'INDEX_FN': INDEX_FN,\n",
    "                            # 'ID_COL_NAME': 'HYBAS_ID',\n",
    "                            # 'TILE_NUM':TILE_NUM,\n",
    "                            # 'INDEX_LYR': INDEX_LYR,\n",
    "                            # data is accessed via its footprint, with a 's3_path' col identifying the s3 locations of each tile\n",
    "                            'RASTER_NAME': 'terrapulse_tcc_slope',\n",
    "                            'COVAR_TILE_FN': 'https://maap-ops-workspace.s3.amazonaws.com/shared/montesano/databank/footprints/footprints_terrapulse-pub-data_tcc_slope-s3.gpkg',\n",
    "                            'IN_COVAR_S3_COL': 's3_path',\n",
    "                            'OUTDIR': OUTDIR,\n",
    "                            'NODATA_VAL': 255,\n",
    "                            'OUTPUT_CLIP_COG_FN':'',\n",
    "                            'CREDENTIALS_FN': None\n",
    "                        },\n",
    "                # tcc pvalue\n",
    "                {\n",
    "                            # #'INDEX_FN': '/projects/my-public-bucket/boreal_tiles_v003.gpkg',\n",
    "                            # 'INDEX_FN': INDEX_FN,\n",
    "                            # 'ID_COL_NAME': 'HYBAS_ID',\n",
    "                            # 'TILE_NUM':TILE_NUM,\n",
    "                            # 'INDEX_LYR': INDEX_LYR,\n",
    "                            # data is accessed via its footprint, with a 's3_path' col identifying the s3 locations of each tile\n",
    "                            'RASTER_NAME': 'terrapulse_tcc_pvalue',\n",
    "                            'COVAR_TILE_FN': 'https://maap-ops-workspace.s3.amazonaws.com/shared/montesano/databank/footprints/footprints_terrapulse-pub-data_tcc_pvalue-s3.gpkg',\n",
    "                            'IN_COVAR_S3_COL': 's3_path',\n",
    "                            'OUTDIR': OUTDIR,\n",
    "                            'NODATA_VAL': 255,\n",
    "                            'OUTPUT_CLIP_COG_FN':'',\n",
    "                            'CREDENTIALS_FN': None\n",
    "                        }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b1a50ff9-688b-4a79-8897-76bd25bf8f4c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17052"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HYBAS_ID_LIST = gpd.read_file(INDEX_FN).HYBAS_ID.to_list()\n",
    "len(HYBAS_ID_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2f476337-497f-46b2-95cd-ee9dbb819643",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(build_stack)\n",
    "\n",
    "def run_build_stack(HYBAS_ID):\n",
    "    VECTOR_DICT['TILE_NUM'] = HYBAS_ID\n",
    "    build_stack.build_stack_list(\n",
    "                            covar_dict_list=BUILD_STACK_DICT_LIST, \n",
    "                            vector_dict=VECTOR_DICT, \n",
    "                             tile_buffer_m=0, \n",
    "                             res=30, clip=True,\n",
    "                             output_dir='/projects/my-public-bucket/databank/boreal_height_cmip6/output/build_stack_basin_clips',\n",
    "                             height=None, width=None,\n",
    "                             MAKE_DF=False\n",
    "                            )\n",
    "    \n",
    "def rename_columns(GDF, bandname, stats_list):\n",
    "    if stats_list is not None:\n",
    "       \n",
    "        names_list = ['val_'+ bandname + '_' + s for s in stats_list]\n",
    "        rename_dict = dict(zip(stats_list, names_list))      \n",
    "        GDF = GDF.rename(columns = rename_dict)\n",
    "        \n",
    "    return GDF\n",
    "\n",
    "def extract_zonal_gdf_poly(HYBAS_ID, bandnames: list, GDF_fn, \n",
    "                           DATA_DIR = '/projects/my-public-bucket/databank/boreal_height_cmip6/output/build_stack_basin_clips',\n",
    "                           OUTDIR = '/projects/my-public-bucket/databank/boreal_height_cmip6/output/zonal_stats',\n",
    "                           ndval_list=[255,-9999], \n",
    "                           stats_list = ['max','min','median','mean','percentile_02','percentile_25','percentile_75','percentile_98','count']):\n",
    "    \n",
    "    r_fn = glob.glob(f'{DATA_DIR}/*{HYBAS_ID}*.tif')[0]\n",
    "    GDF = gpd.read_file(GDF_fn)\n",
    "    GDF = GDF[GDF.HYBAS_ID == HYBAS_ID]\n",
    "    \n",
    "    from rasterstats import zonal_stats\n",
    "    import numpy as np\n",
    "    import rasterio\n",
    "    \n",
    "    gdf_list = []\n",
    "    \n",
    "    with rasterio.open(r_fn) as r_src:\n",
    "        print(\"\\tExtracting raster values from: \", r_fn)\n",
    "        df_list = []\n",
    "        for i, bandname in enumerate(bandnames):\n",
    "            \n",
    "            bnum = i + 1\n",
    "            #print(bnum)\n",
    "            \n",
    "            # Get array\n",
    "            array = r_src.read(bnum)\n",
    "            array = array.astype('float64')\n",
    "            \n",
    "            for ndval in ndval_list: array[array==ndval] = np.nan\n",
    "\n",
    "            df = pd.DataFrame(\n",
    "                    zonal_stats(\n",
    "                        vectors=GDF.to_crs(r_src.crs), \n",
    "                        raster= array,#r_src.read(bnum, masked=True),\n",
    "                        affine= r_src.transform,\n",
    "                        stats=stats_list,\n",
    "                        nodata=np.nan\n",
    "                    )\n",
    "            )\n",
    "\n",
    "            # Rename cols\n",
    "            df = rename_columns(df, bandname, stats_list)\n",
    "            df_list.append(df)\n",
    "            \n",
    "\n",
    "        df_final = pd.concat(df_list, axis=1)\n",
    "        final_gdf = GDF.reset_index().join(df_final.reset_index(drop=True), how='left')\n",
    "\n",
    "        gdf_list.append(final_gdf)\n",
    "            \n",
    "    # Write the table of zonal stats on each band for current HYBAS_ID   \n",
    "    hybas_id_gdf = pd.concat(gdf_list)\n",
    "    hybas_id_gdf.to_file(os.path.join(OUTDIR, os.path.basename(r_fn).split('.tif')[0] + '_zonalstats.gpkg'), driver = 'GPKG')\n",
    "    \n",
    "    return pd.concat(gdf_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345423c7-da21-4fb9-8144-8b589248ef71",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Plot basins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8139e992-fff4-40da-81a6-7be9fd27dfc2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #zonal_smry_gdf = pd.concat(returned_stuff)\n",
    "# with Pool(processes=25) as pool:\n",
    "#     gdf_list = pool.map(partial(gpd.read_file), glob.glob(ZONAL_DIR + '/*.gpkg'))\n",
    "# #zonal_smry_gdf = pd.concat([gpd.read_file(f) for f in glob.glob(OUTDIR + '/*.gpkg')])\n",
    "# zonal_smry_gdf = pd.concat(gdf_list)                       \n",
    "# ax = zonal_smry_gdf.to_crs(4326).plot(column='val_terrapulse_tcc_slope_median', cmap='BrBG', legend=True, vmin=-0.5, vmax=0.5)\n",
    "# ax = ctx.add_basemap(ax=ax, crs=4326, source = ctx.providers.Esri.WorldGrayCanvas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b580a6d-3b65-45e9-9488-505e88e60905",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LIST_GPKG_DONE = gpd.read_file('/projects/my-public-bucket/databank/boreal_height_cmip6/output/hydrobasins_L08_patterns_tte_boreal_tundra_3995_tcc_trends_part1.gpkg').HYBAS_ID.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "75540e4c-f890-4adf-8956-8626e6543593",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15068 basin clip cogs that have been processed.\n",
      "1984 basin clip cogs still missing\n",
      "9105 zonal GPKGs that have been processed.\n",
      "5963 zonal GPKGs available to process \n"
     ]
    }
   ],
   "source": [
    "# Get missing\n",
    "LIST_HYBAS_ID_COG_FINISHED= [int(os.path.basename(f).split('_')[2]) for f in glob.glob(OUTDIR + '/*cog.tif' )]\n",
    "print(f'{len(LIST_HYBAS_ID_COG_FINISHED)} basin clip cogs that have been processed.')\n",
    "\n",
    "LIST_HYBAS_ID_COG_MISSING = [id for id in HYBAS_ID_LIST if id not in LIST_HYBAS_ID_COG_FINISHED]\n",
    "print(f'{len(LIST_HYBAS_ID_COG_MISSING)} basin clip cogs still missing')\n",
    "\n",
    "LIST_HYBAS_ID_GPKG_FINISHED= [int(os.path.basename(f).split('_')[2]) for f in glob.glob(ZONAL_DIR + '/*cog_zonalstats.gpkg' )] + LIST_GPKG_DONE\n",
    "                            \n",
    "print(f'{len(LIST_HYBAS_ID_GPKG_FINISHED)} zonal GPKGs that have been processed.')\n",
    "\n",
    "LIST_HYBAS_ID_GPKG_MISSING = [id for id in LIST_HYBAS_ID_COG_FINISHED if id not in LIST_HYBAS_ID_GPKG_FINISHED]\n",
    "print(f'{len(LIST_HYBAS_ID_GPKG_MISSING)} zonal GPKGs available to process ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c61ffe-c7c7-4564-a7a6-83ecc4e65e58",
   "metadata": {},
   "source": [
    "### Step [1]: build stack of tcc_slope and tcc_pvalue for basins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fd8fc5-21a6-4f17-a5f4-a3e8bddf418f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%%capture captured_output_text\n",
    "\n",
    "with Pool(processes=25) as pool:\n",
    "    pool.map(partial(run_build_stack), LIST_HYBAS_ID_COG_MISSING)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c945496-f542-4e4e-a0b5-d3a34b58bcb7",
   "metadata": {},
   "source": [
    "### Step [2]: get zonal stats of stack for basin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "16b25b36-7771-4afe-a23b-da7638d54970",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Pool(processes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m25\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m pool:\n\u001b[0;32m----> 2\u001b[0m     returned_stuff \u001b[38;5;241m=\u001b[39m \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mextract_zonal_gdf_poly\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43mbandnames\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43md\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRASTER_NAME\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mBUILD_STACK_DICT_LIST\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43mGDF_fn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mINDEX_FN\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mLIST_HYBAS_ID_GPKG_MISSING\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                             \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/multiprocessing/pool.py:367\u001b[0m, in \u001b[0;36mPool.map\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    363\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;124;03m    Apply `func` to each element in `iterable`, collecting the results\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;124;03m    in a list that is returned.\u001b[39;00m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 367\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapstar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/multiprocessing/pool.py:768\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 768\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mready():\n\u001b[1;32m    770\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/multiprocessing/pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwait\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 765\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_event\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/threading.py:607\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    605\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 607\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%capture captured_output_text\n",
    "\n",
    "with Pool(processes=25) as pool:\n",
    "    returned_stuff = pool.map(partial(extract_zonal_gdf_poly, \n",
    "                                      bandnames = [d['RASTER_NAME'] for d in BUILD_STACK_DICT_LIST], \n",
    "                                      GDF_fn = INDEX_FN ), \n",
    "                              LIST_HYBAS_ID_GPKG_MISSING\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fb329bbd-c0fa-4124-9943-296ffead65c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 1: kill: (19113) - No such process\n"
     ]
    }
   ],
   "source": [
    "for j in list(range(19093, 19119)):\n",
    "    !kill -9 $j"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
